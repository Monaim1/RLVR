{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31029eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install docling trl peft accelerate bitsandbytes --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62326ff",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecad6c25",
   "metadata": {},
   "source": [
    "the dataset was generated by converting raw json patents into a PDF.\n",
    "\n",
    "The goal is to train an SLM to re-generate the gold json given it's pre-processed text format with Docling.\n",
    "\n",
    "The train and validation manifests are already pre-processed with DOCLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c828c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e91ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': \"Extract the following fields as JSON only (no extra text). Fields: {publication_number, application_number, patent_number, date_published, filing_date, patent_issue_date, abandon_date, decision, main_cpc_label, main_ipcr_label, title, abstract, summary, claims}\\n\\nDOCUMENT:\\n## Intelligent Drug and/or Fluid Delivery System to Optimizing Medical Treatment or Therapy Using Pharmacodynamic and/or Pharamacokinetic Data\\n\\nPatent Number:\\n\\n9950112\\n\\nApplication Number:\\n\\n13817165\\n\\nPublication Date:\\n\\nN/A\\n\\nApplicant:\\n\\nN/A\\n\\nInventors:\\n\\nN/A\\n\\nThis document contains information about the patent's abstract, claims, and detailed description.\\n\\n## Abstract\\n\\nA pharmacodynamic (PD), pharmacokinetic (PK), or both and PK guided infusion device, system and method optimizes the safety and efficacy of various forms of treatment or therapy (e.g., drug and/or fluid) in a variety of health-care and other settings.\\n\\n## Claims\\n\\nReturn strictly a single JSON object with those keys.\",\n",
       " 'gold': {'application_number': '13817165',\n",
       "  'publication_number': 'US20130296823A1-20131107',\n",
       "  'title': 'Intelligent Drug and/or Fluid Delivery System to Optimizing Medical Treatment or Therapy Using Pharmacodynamic and/or Pharamacokinetic Data',\n",
       "  'decision': 'ACCEPTED',\n",
       "  'date_published': '20131107',\n",
       "  'main_cpc_label': 'A61M51723',\n",
       "  'main_ipcr_label': 'A61M5172',\n",
       "  'patent_number': '9950112',\n",
       "  'filing_date': '20180219',\n",
       "  'patent_issue_date': '20180424',\n",
       "  'abandon_date': '',\n",
       "  'abstract': 'A pharmacodynamic (PD), pharmacokinetic (PK), or both and PK guided infusion device, system and method optimizes the safety and efficacy of various forms of treatment or therapy (e.g., drug and/or fluid) in a variety of health-care and other settings.'},\n",
       " 'patent_id': 'patent_US20130296823A1-20131107'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fields expected in gold JSONs\n",
    "RELEVANT_FIELDS: List[str] = [\n",
    "    \"publication_number\",\n",
    "    \"application_number\",\n",
    "    \"patent_number\",\n",
    "    \"date_published\",\n",
    "    \"filing_date\",\n",
    "    \"patent_issue_date\",\n",
    "    \"abandon_date\",\n",
    "    \"decision\",\n",
    "    \"main_cpc_label\",\n",
    "    \"main_ipcr_label\",\n",
    "    \"title\",\n",
    "    \"abstract\",\n",
    "    \"summary\",\n",
    "    \"claims\",\n",
    "]\n",
    "\n",
    "\n",
    "def load_manifest(path: str) -> pd.DataFrame:\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "class PatentIEDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for RLVR/GRPO IE on patent PDFs.\n",
    "\n",
    "    Expects a manifest DataFrame with columns:\n",
    "      - patent_id\n",
    "      - pdf_path\n",
    "      - gold_json_path\n",
    "      - text (optional if `preload_text=True`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, manifest_df: pd.DataFrame, preload_text: bool = False):\n",
    "        self.df = manifest_df.reset_index(drop=True)\n",
    "        self.preload_text = preload_text\n",
    "\n",
    "        if self.preload_text and \"text\" not in self.df.columns:\n",
    "            # Pre-extract on the fly (prefer preprocessing pass for speed)\n",
    "            self.df = self.df.copy()\n",
    "            self.df[\"text\"] = self.df[\"pdf_path\"].apply(self._load_pdf_text)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _docling_converter(self):\n",
    "        try:\n",
    "            from docling.document_converter import DocumentConverter, InputFormat, PdfFormatOption\n",
    "            from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "        except Exception as e:\n",
    "            return None\n",
    "        return DocumentConverter(\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_options=PdfPipelineOptions(\n",
    "                        do_ocr=False,\n",
    "                        force_backend_text=True,\n",
    "                        do_table_structure=False,\n",
    "                        generate_picture_images=False,\n",
    "                        generate_page_images=False,\n",
    "                        generate_table_images=False,\n",
    "                    )\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def _load_pdf_text(self, pdf_path: str) -> str:\n",
    "        converter = self._docling_converter()\n",
    "        if converter is not None:\n",
    "            res = converter.convert(str(pdf_path))\n",
    "            return res.document.export_to_text()\n",
    "        # Fallback to PyMuPDF if Docling unavailable\n",
    "        import fitz  # type: ignore\n",
    "        doc = fitz.open(pdf_path)\n",
    "        return \"\\n\\n\".join(page.get_text(\"text\") for page in doc)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        row = self.df.iloc[i]\n",
    "        text = (\n",
    "            row[\"text\"] if (\"text\" in row and self.preload_text) else self._load_pdf_text(row[\"pdf_path\"])\n",
    "        )\n",
    "        gold = json.load(open(row[\"gold_json_path\"], \"r\"))\n",
    "\n",
    "        fields_str = \", \".join(RELEVANT_FIELDS)\n",
    "        prompt = (\n",
    "            \"Extract the following fields as JSON only (no extra text). \"\n",
    "            f\"Fields: {{{fields_str}}}\\n\\n\"\n",
    "            f\"DOCUMENT:\\n{text}\\n\\n\"\n",
    "            \"Return strictly a single JSON object with those keys.\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_text\": prompt,\n",
    "            \"gold\": gold,\n",
    "            \"patent_id\": row[\"patent_id\"],\n",
    "        }\n",
    "\n",
    "\n",
    "train_manifest = load_manifest(\"Patent_Data/train_manifest.parquet\")\n",
    "val_manifest = load_manifest(\"Patent_Data/val_manifest.parquet\")\n",
    "\n",
    "patent_train_dataset = PatentIEDataset(train_manifest, preload_text=True)\n",
    "patent_val_dataset = PatentIEDataset(val_manifest, preload_text=True)\n",
    "patent_train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed202e7",
   "metadata": {},
   "source": [
    "## Reward design for Information Extraction (IE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020222bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from difflib import SequenceMatcher\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "\n",
    "\n",
    "\n",
    "RELEVANT_FIELDS: List[str] = [\n",
    "    \"publication_number\",\n",
    "    \"application_number\",\n",
    "    \"patent_number\",\n",
    "    \"date_published\",\n",
    "    \"filing_date\",\n",
    "    \"patent_issue_date\",\n",
    "    \"abandon_date\",\n",
    "    \"decision\",\n",
    "    \"main_cpc_label\",\n",
    "    \"main_ipcr_label\",\n",
    "    \"title\",\n",
    "    \"abstract\",\n",
    "   # \"summary\",\n",
    "    #\"claims\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _first_json(text: str) -> Optional[Dict[str, Any]]:\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        return obj if isinstance(obj, dict) else None\n",
    "    except Exception:\n",
    "        pass\n",
    "    start = text.find(\"{\")\n",
    "    if start == -1:\n",
    "        return None\n",
    "    depth, in_str, esc = 0, False, False\n",
    "    for i in range(start, len(text)):\n",
    "        ch = text[i]\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            elif ch == \"\\\\\":\n",
    "                esc = True\n",
    "            elif ch == '\"':\n",
    "                in_str = False\n",
    "        else:\n",
    "            if ch == '\"':\n",
    "                in_str = True\n",
    "            elif ch == \"{\":\n",
    "                depth += 1\n",
    "            elif ch == \"}\":\n",
    "                depth -= 1\n",
    "                if depth == 0:\n",
    "                    try:\n",
    "                        return json.loads(text[start : i + 1])\n",
    "                    except Exception:\n",
    "                        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def _norm(s: Any, max_len: int = 4000) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    if isinstance(s, (list, tuple)):\n",
    "        s = \"\\n\".join(map(str, s))\n",
    "    s = str(s).lower().strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    if len(s) > max_len:\n",
    "        s = s[:max_len]\n",
    "    return s\n",
    "\n",
    "\n",
    "def _sim(a: str, b: str) -> float:\n",
    "    if not a and not b:\n",
    "        return 1.0\n",
    "    if a == b:\n",
    "        return 1.0\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "def _parse_date(s: Any) -> Optional[datetime]:\n",
    "    if not isinstance(s, str) or not s:\n",
    "        return None\n",
    "    for fmt in (\"%Y-%m-%d\", \"%Y%m%d\", \"%Y/%m/%d\"):\n",
    "        try:\n",
    "            return datetime.strptime(s.strip(), fmt)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def compute_reward(\n",
    "    model_output_text: str,\n",
    "    gold: Dict[str, Any],\n",
    "    weights: Tuple[float, float, float, float] = (0.5, 0.4, 0.1, 0.05),\n",
    ") -> Tuple[float, Dict[str, float]]:\n",
    "    pred = _first_json(model_output_text)\n",
    "    validity = int(isinstance(pred, dict) and set(RELEVANT_FIELDS).issubset(set(pred.keys())))\n",
    "\n",
    "    # Field-level similarity (only where gold is non-empty)\n",
    "    sims: Dict[str, float] = {}\n",
    "    use_fields: List[str] = []\n",
    "    if isinstance(pred, dict):\n",
    "        for k in RELEVANT_FIELDS:\n",
    "            g = gold.get(k)\n",
    "            if g is None or (isinstance(g, str) and g.strip() == \"\"):\n",
    "                sims[k] = 0.0\n",
    "                continue\n",
    "            p = pred.get(k)\n",
    "            score = _sim(_norm(g), _norm(p))\n",
    "            sims[k] = float(score)\n",
    "            use_fields.append(k)\n",
    "    field_mean = sum(sims.get(k, 0.0) for k in use_fields) / max(1, len(use_fields))\n",
    "\n",
    "    # Constraints: dates in order if present\n",
    "    constraints = 0\n",
    "    if isinstance(pred, dict):\n",
    "        fd = _parse_date(pred.get(\"filing_date\"))\n",
    "        pd = _parse_date(pred.get(\"date_published\"))\n",
    "        id_ = _parse_date(pred.get(\"patent_issue_date\"))\n",
    "        ok = True\n",
    "        if fd and pd:\n",
    "            ok = ok and (fd <= pd)\n",
    "        if fd and id_:\n",
    "            ok = ok and (fd <= id_)\n",
    "        if pd and id_:\n",
    "            ok = ok and (pd <= id_)\n",
    "        constraints = int(ok)\n",
    "\n",
    "    # Format bonus: exact keys + ISO dates if present\n",
    "    fmt = 0.0\n",
    "    if isinstance(pred, dict) and set(pred.keys()) == set(RELEVANT_FIELDS):\n",
    "        iso_ok = True\n",
    "        for k in (\"filing_date\", \"date_published\", \"patent_issue_date\", \"abandon_date\"):\n",
    "            v = pred.get(k)\n",
    "            if v is None or (isinstance(v, str) and v.strip() == \"\"):\n",
    "                continue\n",
    "            try:\n",
    "                datetime.strptime(str(v).strip(), \"%Y-%m-%d\")\n",
    "            except Exception:\n",
    "                iso_ok = False\n",
    "                break\n",
    "        if iso_ok:\n",
    "            fmt = 0.1\n",
    "\n",
    "    w1, w2, w3, w4 = weights\n",
    "    total = w1 * validity + w2 * field_mean + w3 * constraints + w4 * fmt\n",
    "    total = max(0.0, min(1.0, float(total)))\n",
    "\n",
    "    return total, {\n",
    "        \"validity\": float(validity),\n",
    "        \"field_mean\": float(field_mean),\n",
    "        \"constraints\": float(constraints),\n",
    "        \"format\": float(fmt),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "476d1939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, {'validity': 0.0, 'field_mean': 0.0, 'constraints': 0.0, 'format': 0.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_reward(\n",
    "    '{\"publication_number\": \"US1234567A\", \"application_number\": \"US12/345,678\", \"patent_number\": \"1234567\", \"date_published\": \"2020-01-01\", \"filing_date\": \"2018-06-15\", \"patent_issue_date\": \"2021-05-20\", \"abandon_date\": \"\", \"decision\": \"granted\", \"main_cpc_label\": \"G06F17/30\", \"main_ipcr_label\": \"G06F17/30\", \"title\": \"Innovative Widget\", \"abstract\": \"An innovative widget that improves efficiency.\", }',\n",
    "    {\n",
    "        \"publication_number\": \"US1234567A\",\n",
    "        \"application_number\": \"US12/345,678\",\n",
    "        \"patent_number\": \"1234567\",\n",
    "        \"date_published\": \"2020-01-01\",\n",
    "        \"filing_date\": \"2018-06-15\",\n",
    "        \"patent_issue_date\": \"2021-05-20\",\n",
    "        \"abandon_date\": \"\",\n",
    "        \"decision\": \"granted\",\n",
    "        \"main_cpc_label\": \"G06F17/30\",\n",
    "        \"main_ipcr_label\": \"G06F17/30\",\n",
    "        \"title\": \"Innovative Widget\",\n",
    "        \"abstract\": \"An innovative widget that improves efficiency.\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60bfc91",
   "metadata": {},
   "source": [
    "## SFT warm-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8ad9943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mounselam/.pyenv/versions/3.12.3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 590\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def get_prompt(text: str) -> str:\n",
    "    fields_str = \", \".join(RELEVANT_FIELDS)\n",
    "    return (\n",
    "        \"Extract the following fields as JSON only (no extra text). \"\n",
    "        f\"Fields: {{{fields_str}}}\\n\\n\"\n",
    "        f\"DOCUMENT:\\n{text}\\n\\n\"\n",
    "        \"Return strictly a single JSON object with those keys.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def df_to_sft_dataset(manifest_path: str, limit: int | None = None) -> Dataset:\n",
    "    df = pd.read_parquet(manifest_path)\n",
    "    if limit:\n",
    "        df = df.head(limit)\n",
    "    if \"text\" not in df.columns:\n",
    "        raise ValueError(\"Manifest must contain a 'text' column. Re-run generateDatasets.py to pre-extract text.\")\n",
    "\n",
    "    prompts: List[str] = [get_prompt(t) for t in df[\"text\"].tolist()]\n",
    "\n",
    "    # Load gold JSON content as the target response\n",
    "    answers: List[str] = []\n",
    "    for p in df[\"gold_json_path\"].tolist():\n",
    "        with open(p, \"r\") as f:\n",
    "            answers.append(f.read())\n",
    "\n",
    "    # Single text field: prompt + answer delimited\n",
    "    samples = [\n",
    "        {\n",
    "            \"text\": f\"{prompt}\\n\\n<answer>\\n{answer}\\n</answer>\",\n",
    "        }\n",
    "        for prompt, answer in zip(prompts, answers)\n",
    "    ]\n",
    "    return Dataset.from_list(samples)\n",
    "\n",
    "train_ds = df_to_sft_dataset(\"Patent_Data/train_manifest.parquet\")\n",
    "val_ds = df_to_sft_dataset(\"Patent_Data/val_manifest.parquet\")\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding-free training is enabled, but the attention implementation is not set to a supported flash attention variant. Padding-free training flattens batches into a single sequence, and only the following implementations are known to reliably support this: flash_attention_2, flash_attention_3, kernels-community/flash-attn, kernels-community/flash-attn3, kernels-community/vllm-flash-attn3. Using other implementations may lead to unexpected behavior. To ensure compatibility, set `attn_implementation` in the model configuration to one of these supported options or verify that your attention mechanism can handle flattened sequences.\n",
      "You are using packing, but the attention implementation is not set to a supported flash attention variant. Packing gathers multiple samples into a single sequence, and only the following implementations are known to reliably support this: flash_attention_2, flash_attention_3, kernels-community/flash-attn, kernels-community/flash-attn3, kernels-community/vllm-flash-attn3. Using other implementations may lead to cross-contamination between samples. To avoid this, either disable packing by setting `packing=False`, or set `attn_implementation` in the model configuration to one of these supported options.\n",
      "Adding EOS to train dataset: 100%|██████████| 590/590 [00:00<00:00, 79731.91 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 590/590 [00:00<00:00, 1276.64 examples/s]\n",
      "Packing train dataset: 100%|██████████| 590/590 [00:00<00:00, 141448.38 examples/s]\n",
      "Adding EOS to eval dataset: 100%|██████████| 107/107 [00:00<00:00, 48091.57 examples/s]\n",
      "Tokenizing eval dataset: 100%|██████████| 107/107 [00:00<00:00, 977.21 examples/s] \n",
      "Packing eval dataset: 100%|██████████| 107/107 [00:00<00:00, 39956.42 examples/s]\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
      "/Users/mounselam/.pyenv/versions/3.12.3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/59 52:46 < 1:12:33, 0.01 it/s, Epoch 0.43/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8 else torch.float16\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.config.use_cache = False  # needed if you enable gradient checkpointing\n",
    "\n",
    "# LoRA config (common: q_proj, k_proj, v_proj, o_proj)\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "sft_args = SFTConfig(\n",
    "    output_dir=\"qwen3_0p6B_lora\",\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    logging_steps=10,\n",
    "    save_steps=200,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    gradient_checkpointing=True,\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_ratio=0.03,\n",
    "    packing=True,                # packs multiple samples into one sequence to save memory\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,                  # pass the loaded model (not a string)\n",
    "    args=sft_args,\n",
    "    train_dataset=train_ds,       # your datasets\n",
    "    eval_dataset=val_ds,\n",
    "    peft_config=peft_config,      # attaches LoRA adapters\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c8789",
   "metadata": {},
   "source": [
    "## RLVR GRPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e4a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aefef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
