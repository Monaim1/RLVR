{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31029eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install docling trl --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62326ff",
   "metadata": {},
   "source": [
    "## Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecad6c25",
   "metadata": {},
   "source": [
    "the dataset was generated by converting raw json patents into a PDF.\n",
    "\n",
    "The goal is to train an SLM to re-generate the gold json given it's pre-processed text format with Docling.\n",
    "\n",
    "The train and validation manifests are already pre-processed with DOCLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c828c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "train_manifest = pd.read_parquet(\"Patent_Data/train_manifest.parquet\")\n",
    "val_manifest = pd.read_parquet(\"Patent_Data/val_manifest.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e91ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': \"Extract the following fields as JSON only (no extra text). Fields: {publication_number, application_number, patent_number, date_published, filing_date, patent_issue_date, abandon_date, decision, main_cpc_label, main_ipcr_label, title, abstract, summary, claims}\\n\\nDOCUMENT:\\n## Intelligent Drug and/or Fluid Delivery System to Optimizing Medical Treatment or Therapy Using Pharmacodynamic and/or Pharamacokinetic Data\\n\\nPatent Number:\\n\\n9950112\\n\\nApplication Number:\\n\\n13817165\\n\\nPublication Date:\\n\\nN/A\\n\\nApplicant:\\n\\nN/A\\n\\nInventors:\\n\\nN/A\\n\\nThis document contains information about the patent's abstract, claims, and detailed description.\\n\\n## Abstract\\n\\nA pharmacodynamic (PD), pharmacokinetic (PK), or both and PK guided infusion device, system and method optimizes the safety and efficacy of various forms of treatment or therapy (e.g., drug and/or fluid) in a variety of health-care and other settings.\\n\\n## Claims\\n\\nReturn strictly a single JSON object with those keys.\",\n",
       " 'gold': {'application_number': '13817165',\n",
       "  'publication_number': 'US20130296823A1-20131107',\n",
       "  'title': 'Intelligent Drug and/or Fluid Delivery System to Optimizing Medical Treatment or Therapy Using Pharmacodynamic and/or Pharamacokinetic Data',\n",
       "  'decision': 'ACCEPTED',\n",
       "  'date_published': '20131107',\n",
       "  'main_cpc_label': 'A61M51723',\n",
       "  'main_ipcr_label': 'A61M5172',\n",
       "  'patent_number': '9950112',\n",
       "  'filing_date': '20180219',\n",
       "  'patent_issue_date': '20180424',\n",
       "  'abandon_date': '',\n",
       "  'abstract': 'A pharmacodynamic (PD), pharmacokinetic (PK), or both and PK guided infusion device, system and method optimizes the safety and efficacy of various forms of treatment or therapy (e.g., drug and/or fluid) in a variety of health-care and other settings.'},\n",
       " 'patent_id': 'patent_US20130296823A1-20131107'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fields expected in gold JSONs\n",
    "RELEVANT_FIELDS: List[str] = [\n",
    "    \"publication_number\",\n",
    "    \"application_number\",\n",
    "    \"patent_number\",\n",
    "    \"date_published\",\n",
    "    \"filing_date\",\n",
    "    \"patent_issue_date\",\n",
    "    \"abandon_date\",\n",
    "    \"decision\",\n",
    "    \"main_cpc_label\",\n",
    "    \"main_ipcr_label\",\n",
    "    \"title\",\n",
    "    \"abstract\",\n",
    "    \"summary\",\n",
    "    \"claims\",\n",
    "]\n",
    "\n",
    "\n",
    "def load_manifest(path: str) -> pd.DataFrame:\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "class PatentIEDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for RLVR/GRPO IE on patent PDFs.\n",
    "\n",
    "    Expects a manifest DataFrame with columns:\n",
    "      - patent_id\n",
    "      - pdf_path\n",
    "      - gold_json_path\n",
    "      - text (optional if `preload_text=True`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, manifest_df: pd.DataFrame, preload_text: bool = False):\n",
    "        self.df = manifest_df.reset_index(drop=True)\n",
    "        self.preload_text = preload_text\n",
    "\n",
    "        if self.preload_text and \"text\" not in self.df.columns:\n",
    "            # Pre-extract on the fly (prefer preprocessing pass for speed)\n",
    "            self.df = self.df.copy()\n",
    "            self.df[\"text\"] = self.df[\"pdf_path\"].apply(self._load_pdf_text)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _docling_converter(self):\n",
    "        try:\n",
    "            from docling.document_converter import DocumentConverter, InputFormat, PdfFormatOption\n",
    "            from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "        except Exception as e:\n",
    "            return None\n",
    "        return DocumentConverter(\n",
    "            format_options={\n",
    "                InputFormat.PDF: PdfFormatOption(\n",
    "                    pipeline_options=PdfPipelineOptions(\n",
    "                        do_ocr=False,\n",
    "                        force_backend_text=True,\n",
    "                        do_table_structure=False,\n",
    "                        generate_picture_images=False,\n",
    "                        generate_page_images=False,\n",
    "                        generate_table_images=False,\n",
    "                    )\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def _load_pdf_text(self, pdf_path: str) -> str:\n",
    "        converter = self._docling_converter()\n",
    "        if converter is not None:\n",
    "            res = converter.convert(str(pdf_path))\n",
    "            return res.document.export_to_text()\n",
    "        # Fallback to PyMuPDF if Docling unavailable\n",
    "        import fitz  # type: ignore\n",
    "        doc = fitz.open(pdf_path)\n",
    "        return \"\\n\\n\".join(page.get_text(\"text\") for page in doc)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        row = self.df.iloc[i]\n",
    "        text = (\n",
    "            row[\"text\"] if (\"text\" in row and self.preload_text) else self._load_pdf_text(row[\"pdf_path\"])\n",
    "        )\n",
    "        gold = json.load(open(row[\"gold_json_path\"], \"r\"))\n",
    "\n",
    "        fields_str = \", \".join(RELEVANT_FIELDS)\n",
    "        prompt = (\n",
    "            \"Extract the following fields as JSON only (no extra text). \"\n",
    "            f\"Fields: {{{fields_str}}}\\n\\n\"\n",
    "            f\"DOCUMENT:\\n{text}\\n\\n\"\n",
    "            \"Return strictly a single JSON object with those keys.\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_text\": prompt,\n",
    "            \"gold\": gold,\n",
    "            \"patent_id\": row[\"patent_id\"],\n",
    "        }\n",
    "\n",
    "patent_train_dataset = PatentIEDataset(train_manifest, preload_text=True)\n",
    "patent_val_dataset = PatentIEDataset(val_manifest, preload_text=True)\n",
    "patent_train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed202e7",
   "metadata": {},
   "source": [
    "## Reward design for Information Extraction (IE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020222bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "from difflib import SequenceMatcher\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "\n",
    "\n",
    "\n",
    "RELEVANT_FIELDS: List[str] = [\n",
    "    \"publication_number\",\n",
    "    \"application_number\",\n",
    "    \"patent_number\",\n",
    "    \"date_published\",\n",
    "    \"filing_date\",\n",
    "    \"patent_issue_date\",\n",
    "    \"abandon_date\",\n",
    "    \"decision\",\n",
    "    \"main_cpc_label\",\n",
    "    \"main_ipcr_label\",\n",
    "    \"title\",\n",
    "    \"abstract\",\n",
    "   # \"summary\",\n",
    "    #\"claims\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _first_json(text: str) -> Optional[Dict[str, Any]]:\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        return obj if isinstance(obj, dict) else None\n",
    "    except Exception:\n",
    "        pass\n",
    "    start = text.find(\"{\")\n",
    "    if start == -1:\n",
    "        return None\n",
    "    depth, in_str, esc = 0, False, False\n",
    "    for i in range(start, len(text)):\n",
    "        ch = text[i]\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            elif ch == \"\\\\\":\n",
    "                esc = True\n",
    "            elif ch == '\"':\n",
    "                in_str = False\n",
    "        else:\n",
    "            if ch == '\"':\n",
    "                in_str = True\n",
    "            elif ch == \"{\":\n",
    "                depth += 1\n",
    "            elif ch == \"}\":\n",
    "                depth -= 1\n",
    "                if depth == 0:\n",
    "                    try:\n",
    "                        return json.loads(text[start : i + 1])\n",
    "                    except Exception:\n",
    "                        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def _norm(s: Any, max_len: int = 4000) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    if isinstance(s, (list, tuple)):\n",
    "        s = \"\\n\".join(map(str, s))\n",
    "    s = str(s).lower().strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    if len(s) > max_len:\n",
    "        s = s[:max_len]\n",
    "    return s\n",
    "\n",
    "\n",
    "def _sim(a: str, b: str) -> float:\n",
    "    if not a and not b:\n",
    "        return 1.0\n",
    "    if a == b:\n",
    "        return 1.0\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "def _parse_date(s: Any) -> Optional[datetime]:\n",
    "    if not isinstance(s, str) or not s:\n",
    "        return None\n",
    "    for fmt in (\"%Y-%m-%d\", \"%Y%m%d\", \"%Y/%m/%d\"):\n",
    "        try:\n",
    "            return datetime.strptime(s.strip(), fmt)\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def compute_reward(\n",
    "    model_output_text: str,\n",
    "    gold: Dict[str, Any],\n",
    "    weights: Tuple[float, float, float, float] = (0.5, 0.4, 0.1, 0.05),\n",
    ") -> Tuple[float, Dict[str, float]]:\n",
    "    pred = _first_json(model_output_text)\n",
    "    validity = int(isinstance(pred, dict) and set(RELEVANT_FIELDS).issubset(set(pred.keys())))\n",
    "\n",
    "    # Field-level similarity (only where gold is non-empty)\n",
    "    sims: Dict[str, float] = {}\n",
    "    use_fields: List[str] = []\n",
    "    if isinstance(pred, dict):\n",
    "        for k in RELEVANT_FIELDS:\n",
    "            g = gold.get(k)\n",
    "            if g is None or (isinstance(g, str) and g.strip() == \"\"):\n",
    "                sims[k] = 0.0\n",
    "                continue\n",
    "            p = pred.get(k)\n",
    "            score = _sim(_norm(g), _norm(p))\n",
    "            sims[k] = float(score)\n",
    "            use_fields.append(k)\n",
    "    field_mean = sum(sims.get(k, 0.0) for k in use_fields) / max(1, len(use_fields))\n",
    "\n",
    "    # Constraints: dates in order if present\n",
    "    constraints = 0\n",
    "    if isinstance(pred, dict):\n",
    "        fd = _parse_date(pred.get(\"filing_date\"))\n",
    "        pd = _parse_date(pred.get(\"date_published\"))\n",
    "        id_ = _parse_date(pred.get(\"patent_issue_date\"))\n",
    "        ok = True\n",
    "        if fd and pd:\n",
    "            ok = ok and (fd <= pd)\n",
    "        if fd and id_:\n",
    "            ok = ok and (fd <= id_)\n",
    "        if pd and id_:\n",
    "            ok = ok and (pd <= id_)\n",
    "        constraints = int(ok)\n",
    "\n",
    "    # Format bonus: exact keys + ISO dates if present\n",
    "    fmt = 0.0\n",
    "    if isinstance(pred, dict) and set(pred.keys()) == set(RELEVANT_FIELDS):\n",
    "        iso_ok = True\n",
    "        for k in (\"filing_date\", \"date_published\", \"patent_issue_date\", \"abandon_date\"):\n",
    "            v = pred.get(k)\n",
    "            if v is None or (isinstance(v, str) and v.strip() == \"\"):\n",
    "                continue\n",
    "            try:\n",
    "                datetime.strptime(str(v).strip(), \"%Y-%m-%d\")\n",
    "            except Exception:\n",
    "                iso_ok = False\n",
    "                break\n",
    "        if iso_ok:\n",
    "            fmt = 0.1\n",
    "\n",
    "    w1, w2, w3, w4 = weights\n",
    "    total = w1 * validity + w2 * field_mean + w3 * constraints + w4 * fmt\n",
    "    total = max(0.0, min(1.0, float(total)))\n",
    "\n",
    "    return total, {\n",
    "        \"validity\": float(validity),\n",
    "        \"field_mean\": float(field_mean),\n",
    "        \"constraints\": float(constraints),\n",
    "        \"format\": float(fmt),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476d1939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, {'validity': 0.0, 'field_mean': 0.0, 'constraints': 0.0, 'format': 0.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_reward(\n",
    "    '{\"publication_number\": \"US1234567A\", \"application_number\": \"US12/345,678\", \"patent_number\": \"1234567\", \"date_published\": \"2020-01-01\", \"filing_date\": \"2018-06-15\", \"patent_issue_date\": \"2021-05-20\", \"abandon_date\": \"\", \"decision\": \"granted\", \"main_cpc_label\": \"G06F17/30\", \"main_ipcr_label\": \"G06F17/30\", \"title\": \"Innovative Widget\", \"abstract\": \"An innovative widget that improves efficiency.\", }',\n",
    "    {\n",
    "        \"publication_number\": \"US1234567A\",\n",
    "        \"application_number\": \"US12/345,678\",\n",
    "        \"patent_number\": \"1234567\",\n",
    "        \"date_published\": \"2020-01-01\",\n",
    "        \"filing_date\": \"2018-06-15\",\n",
    "        \"patent_issue_date\": \"2021-05-20\",\n",
    "        \"abandon_date\": \"\",\n",
    "        \"decision\": \"granted\",\n",
    "        \"main_cpc_label\": \"G06F17/30\",\n",
    "        \"main_ipcr_label\": \"G06F17/30\",\n",
    "        \"title\": \"Innovative Widget\",\n",
    "        \"abstract\": \"An innovative widget that improves efficiency.\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60bfc91",
   "metadata": {},
   "source": [
    "## SFT warm-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282cbf5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "238c8789",
   "metadata": {},
   "source": [
    "## RLVR GRPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e4a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aefef9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
